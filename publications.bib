
@inproceedings{dufumier_contrastive_2021,
	address = {Cham},
	title = {Contrastive {Learning} with {Continuous} {Proxy} {Meta}-data for {3D} {MRI} {Classification}},
	isbn = {978-3-030-87196-3},
	doi = {10.1007/978-3-030-87196-3_6},
	abstract = {Traditional supervised learning with deep neural networks requires a tremendous amount of labelled data to converge to a good solution. For 3D medical images, it is often impractical to build a large homogeneous annotated dataset for a specific pathology. Self-supervised methods offer a new way to learn a representation of the images in an unsupervised manner with a neural network. In particular, contrastive learning has shown great promises by (almost) matching the performance of fully-supervised CNN on vision tasks. Nonetheless, this method does not take advantage of available meta-data, such as participant’s age, viewed as prior knowledge. Here, we propose to leverage continuous proxy metadata, in the contrastive learning framework, by introducing a new loss called y-Aware InfoNCE loss. Specifically, we improve the positive sampling during pre-training by adding more positive examples with similar proxy meta-data with the anchor, assuming they share similar discriminative semantic features. With our method, a 3D CNN model pre-trained on 10k multi-site healthy brain MRI scans can extract relevant features for three classification tasks: schizophrenia, bipolar diagnosis and Alzheimer’s detection. When fine-tuned, it also outperforms 3D CNN trained from scratch on these tasks, as well as state-of-the-art self-supervised methods.},
	language = {en},
	booktitle = {Medical {Image} {Computing} and {Computer} {Assisted} {Intervention} – {MICCAI} 2021},
	publisher = {Springer International Publishing},
	author = {Dufumier, Benoit and Gori, Pietro and Victor, Julie and Grigis, Antoine and Wessa, Michele and Brambilla, Paolo and Favre, Pauline and Polosan, Mircea and McDonald, Colm and Piguet, Camille Marie and Phillips, Mary and Eyler, Lisa and Duchesnay, Edouard},
	editor = {de Bruijne, Marleen and Cattin, Philippe C. and Cotin, Stéphane and Padoy, Nicolas and Speidel, Stefanie and Zheng, Yefeng and Essert, Caroline},
	year = {2021},
	pages = {58--68},
	file = {Full Text PDF:/home/benoit/snap/zotero-snap/common/Zotero/storage/35NGFGDV/Dufumier et al. - 2021 - Contrastive Learning with Continuous Proxy Meta-data for 3D MRI Classification.pdf:application/pdf},
}

@article{chen_identifying_2019,
	title = {Identifying {Solar} {Flare} {Precursors} {Using} {Time} {Series} of {SDO}/{HMI} {Images} and {SHARP} {Parameters}},
	volume = {17},
	copyright = {©2019. American Geophysical Union. All Rights Reserved.},
	issn = {1542-7390},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2019SW002214},
	doi = {10.1029/2019SW002214},
	abstract = {In this paper we present several methods to identify precursors that show great promise for early predictions of solar flare events. A data preprocessing pipeline is built to extract useful data from multiple sources, Geostationary Operational Environmental Satellites and Solar Dynamics Observatory (SDO)/Helioseismic and Magnetic Imager (HMI), to prepare inputs for machine learning algorithms. Two classification models are presented: classification of flares from quiet times for active regions and classification of strong versus weak flare events. We adopt deep learning algorithms to capture both spatial and temporal information from HMI magnetogram data. Effective feature extraction and feature selection with raw magnetogram data using deep learning and statistical algorithms enable us to train classification models to achieve almost as good performance as using active region parameters provided in HMI/Space-Weather HMI-Active Region Patch (SHARP) data files. Case studies show a significant increase in the prediction score around 20 hr before strong solar flare events.},
	language = {en},
	number = {10},
	urldate = {2024-12-29},
	journal = {Space Weather},
	author = {Chen, Yang and Manchester, Ward B. and Hero, Alfred O. and Toth, Gabor and Dufumier, Benoit and Zhou, Tian and Wang, Xiantong and Zhu, Haonan and Sun, Zeyu and Gombosi, Tamas I.},
	year = {2019},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/2019SW002214},
	keywords = {machine learning, prediction, solar flares},
	pages = {1404--1426},
	file = {Full Text PDF:/home/benoit/snap/zotero-snap/common/Zotero/storage/CJ5QUSJ8/Chen et al. - 2019 - Identifying Solar Flare Precursors Using Time Series of SDOHMI Images and SHARP Parameters.pdf:application/pdf;Snapshot:/home/benoit/snap/zotero-snap/common/Zotero/storage/AFX32IY9/2019SW002214.html:text/html},
}

@article{dufumier_openbhb_2022,
	title = {{OpenBHB}: a {Large}-{Scale} {Multi}-{Site} {Brain} {MRI} {Data}-set for {Age} {Prediction} and {Debiasing}},
	volume = {263},
	issn = {1053-8119},
	shorttitle = {{OpenBHB}},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811922007522},
	doi = {10.1016/j.neuroimage.2022.119637},
	abstract = {Prediction of chronological age from neuroimaging in the healthy population is an important issue because the deviations from normal brain age may highlight abnormal trajectories towards brain disorders. As a first step, ML models have emerged to predict chronological age from brain MRI, as a proxy measure of biological age. However, there is currently no consensus w.r.t which Machine Learning (ML) model is best suited for this task, largely because of a lack of public benchmark. Furthermore, new large emerging population neuroimaging datasets are often biased by the acquisition center images are coming from. This bias heavily deteriorates models generalization capacities, especially for Deep Learning (DL) algorithms that are known to overfit rapidly on the simplest features (known as simplicity bias). Here we propose a new public benchmarking resource, namely Open Big Healthy Brains (OpenBHB), along with a challenge for both brain age prediction and site-effect removal through a representation learning framework. OpenBHB is large-scale, gathering {\textgreater}5K 3D T1 brain MRI from Healthy Controls (HC) and highly multi-sites, aggregating {\textgreater}60 centers worldwide and 10 studies. OpenBHB is expected to grow both in terms of available modalities and number of subjects. All OpenBHB datasets are uniformly preprocessed, including quality check, with container technologies that consist in: 3D Voxel-Based Morphometry maps (VBM from CAT12), quasi-raw (simple linear alignment of images), and Surface-Based Morphometry indices (SBM, from FreeSurfer). The OpenBHB challenge is permanent and we provide all tools, materials and tutorials for participants to easily submit and benchmark their model against each other on a public leaderboard.},
	urldate = {2024-12-29},
	journal = {NeuroImage},
	author = {Dufumier, Benoit and Grigis, Antoine and Victor, Julie and Ambroise, Corentin and Frouin, Vincent and Duchesnay, Edouard},
	month = nov,
	year = {2022},
	pages = {119637},
	file = {ScienceDirect Snapshot:/home/benoit/snap/zotero-snap/common/Zotero/storage/5AB23DQN/S1053811922007522.html:text/html},
}

@inproceedings{barbano_unbiased_2023,
	title = {Unbiased {Supervised} {Contrastive} {Learning}},
	url = {http://arxiv.org/abs/2211.05568},
	doi = {10.48550/arXiv.2211.05568},
	abstract = {Many datasets are biased, namely they contain easy-to-learn features that are highly correlated with the target class only in the dataset but not in the true underlying distribution of the data. For this reason, learning unbiased models from biased data has become a very relevant research topic in the last years. In this work, we tackle the problem of learning representations that are robust to biases. We ﬁrst present a margin-based theoretical framework that allows us to clarify why recent contrastive losses (InfoNCE, SupCon, etc.) can fail when dealing with biased data. Based on that, we derive a novel formulation of the supervised contrastive loss ( -SupInfoNCE), providing more accurate control of the minimal distance between positive and negative samples. Furthermore, thanks to our theoretical framework, we also propose FairKL, a new debiasing regularization loss, that works well even with extremely biased data. We validate the proposed losses on standard vision datasets including CIFAR10, CIFAR100, and ImageNet, and we assess the debiasing capability of FairKL with -SupInfoNCE, reaching stateof-the-art performance on a number of biased datasets, including real instances of biases “in the wild”.},
	language = {en},
	urldate = {2024-12-29},
	booktitle = {International {Conference} on {Learning} {Representations} – {ICLR} 2023},
	author = {Barbano, Carlo Alberto and Dufumier, Benoit and Tartaglione, Enzo and Grangetto, Marco and Gori, Pietro},
	month = may,
	year = {2023},
	note = {arXiv:2211.05568 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {PDF:/home/benoit/snap/zotero-snap/common/Zotero/storage/2ZYSBCW5/Barbano et al. - 2023 - Unbiased Supervised Contrastive Learning.pdf:application/pdf},
}

@misc{dufumier_benchmarking_2023,
	title = {Benchmarking {CNN} on {3D} {Anatomical} {Brain} {MRI}: {Architectures}, {Data} {Augmentation} and {Deep} {Ensemble} {Learning}},
	shorttitle = {Benchmarking {CNN} on {3D} {Anatomical} {Brain} {MRI}},
	url = {http://arxiv.org/abs/2106.01132},
	doi = {10.48550/arXiv.2106.01132},
	abstract = {Deep Learning (DL) and speciﬁcally CNN models have become a de facto method for a wide range of vision tasks, outperforming traditional machine learning (ML) methods. Consequently, they drew a lot of attention in the neuroimaging ﬁeld in particular for phenotype prediction or computer-aided diagnosis. However, most of the current studies often deal with small single-site cohorts, along with a speciﬁc pre-processing pipeline and custom CNN architectures, which make them difﬁcult to compare to. We propose an extensive benchmark of recent state-of-the-art (SOTA) 3D CNN, evaluating also the beneﬁts of data augmentation and deep ensemble learning, on both Voxel-Based Morphometry (VBM) pre-processing and minimally preprocessed quasi-raw images. Experiments were conducted on a large heterogeneous multi-site 3D brain anatomical MRI data-set comprising N = 10k scans on 3 challenging tasks: age prediction, sex classiﬁcation, and schizophrenia diagnosis. We found that all models provide signiﬁcantly better predictions with VBM images than quasi-raw data. This ﬁnding evolved as the training set approaches 10k samples where quasi-raw data almost reach the performance of VBM. Moreover, we showed that linear models perform comparably with SOTA CNN on VBM data. We also demonstrated that DenseNet and tiny-DenseNet, a lighter version that we proposed, provide a good compromise in terms of performance in all data regime. Therefore, we suggest to employ them as the architectures by default. Critically, we also showed that current CNN are still very biased towards the acquisition site, even when trained with N = 10k multi-site images. In this context, VBM pre-processing provides an efﬁcient way to limit this site effect. Surprisingly, we did not ﬁnd any clear beneﬁt from data augmentation techniques - and more recently proposed MRI artefacts for brain MRI. Finally, we also showed that big CNN models were not well calibrated when trained with small brain MRI data-sets and we empirically proved that deep ensemble learning is well suited to re-calibrate them without sacriﬁcing performance.},
	language = {en},
	urldate = {2024-12-29},
	publisher = {arXiv},
	author = {Dufumier, Benoit and Gori, Pietro and Battaglia, Ilaria and Victor, Julie and Grigis, Antoine and Duchesnay, Edouard},
	month = apr,
	year = {2023},
	note = {arXiv:2106.01132 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing},
	file = {PDF:/home/benoit/snap/zotero-snap/common/Zotero/storage/KX7UZZT2/Dufumier et al. - 2023 - Benchmarking CNN on 3D Anatomical Brain MRI Architectures, Data Augmentation and Deep Ensemble Lear.pdf:application/pdf},
}

@inproceedings{barbano_contrastive_2023,
	title = {Contrastive {Learning} for {Regression} in {Multi}-{Site} {Brain} {Age} {Prediction}},
	url = {https://ieeexplore.ieee.org/document/10230733},
	doi = {10.1109/ISBI53787.2023.10230733},
	abstract = {Building accurate Deep Learning (DL) models for brain age prediction is a very relevant topic in neuroimaging, as it could help better understand neurodegenerative disorders and find new biomarkers. To estimate accurate and generalizable models, large datasets have been collected, which are often multi-site and multi-scanner. This large heterogeneity negatively affects the generalization performance of DL models since they are prone to overfit site-related noise. Recently, contrastive learning approaches have been shown to be more robust against noise in data or labels. For this reason, we propose a novel contrastive learning regression loss for robust brain age prediction using MRI scans. Our method achieves state-of-the-art performance on the OpenBHB challenge, yielding the best generalization capability and robustness to site-related noise.},
	urldate = {2024-12-29},
	booktitle = {{IEEE} 20th {International} {Symposium} on {Biomedical} {Imaging} – {ISBI} 2023},
	author = {Barbano, Carlo Alberto and Dufumier, Benoit and Duchesnay, Edouard and Grangetto, Marco and Gori, Pietro},
	month = apr,
	year = {2023},
	note = {ISSN: 1945-8452},
	keywords = {Biological system modeling, Biomarkers, brain age, Buildings, contrastive learning, deep learning, Deep learning, Magnetic resonance imaging, MRI, multi-site, Neuroimaging, Predictive models, regression},
	pages = {1--4},
	file = {IEEE Xplore Abstract Record:/home/benoit/snap/zotero-snap/common/Zotero/storage/REWGFFY2/10230733.html:text/html;Submitted Version:/home/benoit/snap/zotero-snap/common/Zotero/storage/9CIW2G3Z/Barbano et al. - 2023 - Contrastive Learning for Regression in Multi-Site Brain Age Prediction.pdf:application/pdf},
}

@misc{dufumier_conditional_2021,
	title = {Conditional {Alignment} and {Uniformity} for {Contrastive} {Learning} with {Continuous} {Proxy} {Labels}},
	url = {http://arxiv.org/abs/2111.05643},
	doi = {10.48550/arXiv.2111.05643},
	abstract = {Contrastive Learning has shown impressive results on natural and medical images, without requiring annotated data. However, a particularity of medical images is the availability of meta-data (such as age or sex) that can be exploited for learning representations. Here, we show that the recently proposed contrastive y-Aware InfoNCE loss, that integrates multi-dimensional meta-data, asymptotically optimizes two properties: conditional alignment and global uniformity. Similarly to [33], conditional alignment means that similar samples should have similar features, but conditionally on the meta-data. Instead, global uniformity means that the (normalized) features should be uniformly distributed on the unit hypersphere, independently of the meta-data. Here, we propose to deﬁne conditional uniformity, relying on the meta-data, that repel only samples with dissimilar metadata. We show that direct optimization of both conditional alignment and uniformity improves the representations, in terms of linear evaluation, on both CIFAR-100 and a brain MRI dataset.},
	language = {en},
	urldate = {2024-12-29},
	publisher = {arXiv},
	author = {Dufumier, Benoit and Gori, Pietro and Victor, Julie and Grigis, Antoine and Duchesnay, Edouard},
	month = nov,
	year = {2021},
	note = {arXiv:2111.05643 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {PDF:/home/benoit/snap/zotero-snap/common/Zotero/storage/3VVX9EWB/Dufumier et al. - 2021 - Conditional Alignment and Uniformity for Contrastive Learning with Continuous Proxy Labels.pdf:application/pdf},
}

@inproceedings{dufumier_integrating_2023,
	title = {Integrating {Prior} {Knowledge} in {Contrastive} {Learning} with {Kernel}},
	url = {https://proceedings.mlr.press/v202/dufumier23a.html},
	abstract = {Data augmentation is a crucial component in unsupervised contrastive learning (CL). It determines how positive samples are defined and, ultimately, the quality of the learned representation. In this work, we open the door to new perspectives for CL by integrating prior knowledge, given either by generative models - viewed as prior representations - or weak attributes in the positive and negative sampling. To this end, we use kernel theory to propose a novel loss, called decoupled uniformity, that i) allows the integration of prior knowledge and ii) removes the positive-negative coupling in the original InfoNCE loss. We draw a connection between contrastive learning and the conditional mean embedding theory to derive tight bounds on the downstream classification loss. In an unsupervised setting, we empirically demonstrate that CL benefits from generative models to improve its representation both on natural and medical images. In a weakly supervised scenario, our framework outperforms other unconditional and conditional CL approaches.},
	language = {en},
	urldate = {2024-12-29},
	booktitle = {Proceedings of the 40th {International} {Conference} on {Machine} {Learning} – {ICML} 2023},
	publisher = {PMLR},
	author = {Dufumier, Benoit and Barbano, Carlo Alberto and Louiset, Robin and Duchesnay, Edouard and Gori, Pietro},
	month = jul,
	year = {2023},
	note = {ISSN: 2640-3498},
	pages = {8851--8878},
	file = {Full Text PDF:/home/benoit/snap/zotero-snap/common/Zotero/storage/NYATCFLN/Dufumier et al. - 2023 - Integrating Prior Knowledge in Contrastive Learning with Kernel.pdf:application/pdf},
}

@article{dufumier_exploring_2024,
	title = {Exploring the potential of representation and transfer learning for anatomical neuroimaging: {Application} to psychiatry},
	volume = {296},
	issn = {1053-8119},
	shorttitle = {Exploring the potential of representation and transfer learning for anatomical neuroimaging},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811924001605},
	doi = {10.1016/j.neuroimage.2024.120665},
	abstract = {The perspective of personalized medicine for brain disorders requires efficient learning models for anatomical neuroimaging-based prediction of clinical conditions. There is now a consensus on the benefit of deep learning (DL) in addressing many medical imaging tasks, such as image segmentation. However, for single-subject prediction problems, recent studies yielded contradictory results when comparing DL with Standard Machine Learning (SML) on top of classical feature extraction. Most existing comparative studies were limited in predicting phenotypes of little clinical interest, such as sex and age, and using a single dataset. Moreover, they conducted a limited analysis of the employed image pre-processing and feature selection strategies. This paper extensively compares DL and SML prediction capacity on five multi-site problems, including three increasingly complex clinical applications in psychiatry namely schizophrenia, bipolar disorder, and Autism Spectrum Disorder (ASD) diagnosis. To compensate for the relative scarcity of neuroimaging data on these clinical datasets, we also evaluate three pre-training strategies for transfer learning from brain imaging of the general healthy population: self-supervised learning, generative modeling and supervised learning with age. Overall, we find similar performance between randomly initialized DL and SML for the three clinical tasks and a similar scaling trend for sex prediction. This was replicated on an external dataset. We also show highly correlated discriminative brain regions between DL and linear ML models in all problems. Nonetheless, we demonstrate that self-supervised pre-training on large-scale healthy population imaging datasets (N≈10k), along with Deep Ensemble, allows DL to learn robust and transferable representations to smaller-scale clinical datasets (N≤1k). It largely outperforms SML on 2 out of 3 clinical tasks both in internal and external test sets. These findings suggest that the improvement of DL over SML in anatomical neuroimaging mainly comes from its capacity to learn meaningful and useful abstract representations of the brain anatomy, and it sheds light on the potential of transfer learning for personalized medicine in psychiatry},
	urldate = {2024-12-29},
	journal = {NeuroImage},
	author = {Dufumier, Benoit and Gori, Pietro and Petiton, Sara and Louiset, Robin and Mangin, Jean-François and Grigis, Antoine and Duchesnay, Edouard},
	month = aug,
	year = {2024},
	keywords = {Anatomical neuroimaging, Deep learning, Individual subject prediction, Machine learning, Psychiatric disorders},
	pages = {120665},
	file = {ScienceDirect Snapshot:/home/benoit/snap/zotero-snap/common/Zotero/storage/LQDJ69MC/S1053811924001605.html:text/html;Submitted Version:/home/benoit/snap/zotero-snap/common/Zotero/storage/PBG3MHKP/Dufumier et al. - 2024 - Exploring the potential of representation and transfer learning for anatomical neuroimaging Applica.pdf:application/pdf},
}

@inproceedings{guillon_detection_2021,
	address = {Cham},
	title = {Detection of {Abnormal} {Folding} {Patterns} with {Unsupervised} {Deep} {Generative} {Models}},
	isbn = {978-3-030-87586-2},
	doi = {10.1007/978-3-030-87586-2_7},
	abstract = {Although the main structures of cortical folding are present in each human brain, the folding pattern is unique to each individual. Because of this large normal variability, the identification of abnormal patterns associated to developmental disorders is a complex open challenge. In this paper, we tackle this problem as an anomaly detection task and explore the potential of deep generative models using benchmarks made up of synthetic anomalies. To focus learning on the folding geometry, brain MRI are preprocessed first to deal only with a skeleton-based negative cast of the cortex. A variational auto-encoder is trained to get a representation of the regional variability of the folding pattern of the general population. Then several synthetic benchmark datasets of abnormalities are designed. The latent space expressivity is assessed through classification experiments between control’s and abnormal’s latent codes. Finally, the properties encoded in the latent space are analyzed through perturbation of specific latent dimensions and observation of the resulting modification of the reconstructed images. The results have shown that the latent representation is rich enough to distinguish subtle differences like asymmetries between the right and left hemispheres.},
	language = {en},
	booktitle = {Machine {Learning} in {Clinical} {Neuroimaging}},
	publisher = {Springer International Publishing},
	author = {Guillon, Louise and Cagna, Bastien and Dufumier, Benoit and Chavas, Joël and Rivière, Denis and Mangin, Jean-François},
	editor = {Abdulkadir, Ahmed and Kia, Seyed Mostafa and Habes, Mohamad and Kumar, Vinod and Rondina, Jane Maryam and Tax, Chantal and Wolfers, Thomas},
	year = {2021},
	keywords = {Anomaly benchmark, Anomaly detection, Brain architecture, Cortical folding, Variational autoencoder},
	pages = {63--72},
	file = {Full Text PDF:/home/benoit/snap/zotero-snap/common/Zotero/storage/ZSRZ7ZQL/Guillon et al. - 2021 - Detection of Abnormal Folding Patterns with Unsupervised Deep Generative Models.pdf:application/pdf},
}

@inproceedings{louiset_ucsl_2021,
	address = {Cham},
	title = {{UCSL} : {A} {Machine} {Learning} {Expectation}-{Maximization} {Framework} for {Unsupervised} {Clustering} {Driven} by {Supervised} {Learning}},
	isbn = {978-3-030-86486-6},
	shorttitle = {{UCSL}},
	doi = {10.1007/978-3-030-86486-6_46},
	abstract = {Subtype Discovery consists in finding interpretable and consistent sub-parts of a dataset, which are also relevant to a certain supervised task. From a mathematical point of view, this can be defined as a clustering task driven by supervised learning in order to uncover subgroups in line with the supervised prediction. In this paper, we propose a general Expectation-Maximization ensemble framework entitled UCSL (Unsupervised Clustering driven by Supervised Learning). Our method is generic, it can integrate any clustering method and can be driven by both binary classification and regression. We propose to construct a non-linear model by merging multiple linear estimators, one per cluster. Each hyperplane is estimated so that it correctly discriminates - or predict - only one cluster. We use SVC or Logistic Regression for classification and SVR for regression. Furthermore, to perform cluster analysis within a more suitable space, we also propose a dimension-reduction algorithm that projects the data onto an orthonormal space relevant to the supervised task. We analyze the robustness and generalization capability of our algorithm using synthetic and experimental datasets. In particular, we validate its ability to identify suitable consistent sub-types by conducting a psychiatric-diseases cluster analysis with known ground-truth labels. The gain of the proposed method over previous state-of-the-art techniques is about +1.9 points in terms of balanced accuracy. Finally, we make codes and examples available in a scikit-learn-compatible Python package. https://github.com/neurospin-projects/2021\_rlouiset\_ucsl/.},
	language = {en},
	booktitle = {Machine {Learning} and {Knowledge} {Discovery} in {Databases}. {Research} {Track}},
	publisher = {Springer International Publishing},
	author = {Louiset, Robin and Gori, Pietro and Dufumier, Benoit and Houenou, Josselin and Grigis, Antoine and Duchesnay, Edouard},
	editor = {Oliver, Nuria and Pérez-Cruz, Fernando and Kramer, Stefan and Read, Jesse and Lozano, Jose A.},
	year = {2021},
	keywords = {Clustering, Expectation-maximization, Machine learning, Neuroimaging, Subtype discovery},
	pages = {755--771},
	file = {Full Text PDF:/home/benoit/snap/zotero-snap/common/Zotero/storage/ZYKBIIYJ/Louiset et al. - 2021 - UCSL  A Machine Learning Expectation-Maximization Framework for Unsupervised Clustering Driven by S.pdf:application/pdf},
}

@inproceedings{ambroise_mixup_2023,
	address = {Cham},
	title = {{MixUp} {Brain}-{Cortical} {Augmentations} in {Self}-supervised {Learning}},
	isbn = {978-3-031-44858-4},
	doi = {10.1007/978-3-031-44858-4_10},
	abstract = {Learning biological markers for a specific brain pathology is often impaired by the size of the dataset. With the advent of large open datasets in the general population, new learning strategies have emerged. In particular, deep representation learning consists of training a model via pretext tasks that can be used to solve downstream clinical problems of interest. More recently, self-supervised learning provides a rich framework for learning representations by contrasting transformed samples. These methods rely on carefully designed data manipulation to create semantically similar but syntactically different samples. In parallel, domain-specific architectures such as spherical convolutional neural networks can learn from cortical brain measures in order to reveal original biomarkers. Unfortunately, only a few surface-based augmentations exist, and none of them have been applied in a self-supervised learning setting. We perform experiments on two open source datasets: Big Healthy Brain and Healthy Brain Network. We propose new augmentations for the cortical brain: baseline augmentations adapted from classical ones for training convolutional neural networks, typically on natural images, and new augmentations called MixUp. The results suggest that surface-based self-supervised learning performs comparably to supervised baselines, but generalizes better to different tasks and datasets. In addition, the learned representations are improved by the proposed MixUp augmentations. The code is available on GitHub (https://github.com/neurospin-projects/2022\_cambroise\_surfaugment).},
	language = {en},
	booktitle = {Machine {Learning} in {Clinical} {Neuroimaging}},
	publisher = {Springer Nature Switzerland},
	author = {Ambroise, Corentin and Frouin, Vincent and Dufumier, Benoit and Duchesnay, Edouard and Grigis, Antoine},
	editor = {Abdulkadir, Ahmed and Bathula, Deepti R. and Dvornek, Nicha C. and Govindarajan, Sindhuja T. and Habes, Mohamad and Kumar, Vinod and Leonardsen, Esten and Wolfers, Thomas and Xiao, Yiming},
	year = {2023},
	keywords = {Brain structural MRI, Data augmentation, Self-supervised learning, Spherical convolutional neural networks},
	pages = {102--111},
	file = {Full Text PDF:/home/benoit/snap/zotero-snap/common/Zotero/storage/X9KY7FIP/Ambroise et al. - 2023 - MixUp Brain-Cortical Augmentations in Self-supervised Learning.pdf:application/pdf},
}

@misc{barbano_anatomical_2024,
	title = {Anatomical {Foundation} {Models} for {Brain} {MRIs}},
	url = {http://arxiv.org/abs/2408.07079},
	doi = {10.48550/arXiv.2408.07079},
	abstract = {Deep Learning (DL) in neuroimaging has become increasingly relevant for detecting neurological conditions and neurodegenerative disorders. One of the most predominant biomarkers in neuroimaging is represented by brain age, which has been shown to be a good indicator for different conditions, such as Alzheimer’s Disease. Using brain age for weakly supervised pre-training of DL models in transfer learning settings has also recently shown promising results, especially when dealing with data scarcity of different conditions. On the other hand, anatomical information of brain MRIs (e.g. cortical thickness) can provide important information for learning good representations that can be transferred to many downstream tasks. In this work, we propose AnatCL, an anatomical foundation model for brain MRIs that i.) leverages anatomical information in a weakly contrastive learning approach, and ii.) achieves stateof-the-art performances across many different downstream tasks. To validate our approach we consider 12 different downstream tasks for the diagnosis of different conditions such as Alzheimer’s Disease, autism spectrum disorder, and schizophrenia. Furthermore, we also target the prediction of 10 different clinical assessment scores using structural MRI data. Our findings show that incorporating anatomical information during pre-training leads to more robust and generalizable representations. Pre-trained models can be found at: https://github.com/EIDOSLAB/AnatCL.},
	language = {en},
	urldate = {2024-12-29},
	publisher = {arXiv},
	author = {Barbano, Carlo Alberto and Brunello, Matteo and Dufumier, Benoit and Grangetto, Marco},
	month = nov,
	year = {2024},
	note = {arXiv:2408.07079 [eess]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing},
	file = {PDF:/home/benoit/snap/zotero-snap/common/Zotero/storage/54PKJAIE/Barbano et al. - 2024 - Anatomical Foundation Models for Brain MRIs.pdf:application/pdf},
}

@inproceedings{auriau_supervised_2024,
	title = {Supervised {Diagnosis} {Prediction} from {Cortical} {Sulci}: {Toward} the {Discovery} of {Neurodevelopmental} {Biomarkers} in {Mental} {Disorders}},
	shorttitle = {Supervised {Diagnosis} {Prediction} from {Cortical} {Sulci}},
	url = {https://ieeexplore.ieee.org/document/10635738},
	doi = {10.1109/ISBI56570.2024.10635738},
	abstract = {Recent advances in machine learning applied to structural magnetic resonance imaging (sMRI) may highlight abnormalities in brain anatomy associated with mental disorders. These disorders are multifactorial, resulting from a complex combination of neurodevelopmental and environmental factors. In particular, such factors are present in cortical sulci, whose shapes are determined very early in brain development and are a valuable proxy for capturing specifically the neurodevelopmental contribution of brain anatomy. This paper explores whether the shapes of cortical sulci can be used for diagnosis prediction using deep learning models. These models are applied to three mental disorders (autism spectrum disorder, bipolar disorder, and schizophrenia) in large multicentric datasets. We demonstrate that the neurodevelopmental underpinnings of these disorders can be captured with sMRI. Finally, we show the potential of visual explanations of models’ decisions in discovering biomarkers for mental disorders.},
	urldate = {2024-12-29},
	booktitle = {2024 {IEEE} {International} {Symposium} on {Biomedical} {Imaging} ({ISBI})},
	author = {Auriau, Pierre and Grigis, Antoine and Dufumier, Benoit and Louiset, Robin and Chavas, Joël and Gori, Pietro and Mangin, Jean-François and Duchesnay, Edouard},
	month = may,
	year = {2024},
	note = {ISSN: 1945-8452},
	keywords = {Biological system modeling, Biomarkers, cortical sulci, deep learning, Magnetic resonance imaging, Mental disorders, neurodevelopment, Predictive models, psychiatric disorders, Shape, Visualization},
	pages = {1--5},
	file = {IEEE Xplore Abstract Record:/home/benoit/snap/zotero-snap/common/Zotero/storage/RNPR5QEK/10635738.html:text/html;Submitted Version:/home/benoit/snap/zotero-snap/common/Zotero/storage/WQNY9NF6/Auriau et al. - 2024 - Supervised Diagnosis Prediction from Cortical Sulci Toward the Discovery of Neurodevelopmental Biom.pdf:application/pdf},
}

@misc{dufumier_what_2024,
	title = {What to align in multimodal contrastive learning?},
	url = {http://arxiv.org/abs/2409.07402},
	doi = {10.48550/arXiv.2409.07402},
	abstract = {Humans perceive the world through multisensory integration, blending the information of different modalities to adapt their behavior. Contrastive learning offers an appealing solution for multimodal self-supervised learning. Indeed, by considering each modality as a different view of the same entity, it learns to align features of different modalities in a shared representation space. However, this approach is intrinsically limited as it only learns shared or redundant information between modalities, while multimodal interactions can arise in other ways. In this work, we introduce CoMM, a Contrastive Multimodal learning strategy that enables the communication between modalities in a single multimodal space. Instead of imposing cross- or intra- modality constraints, we propose to align multimodal representations by maximizing the mutual information between augmented versions of these multimodal features. Our theoretical analysis shows that shared, synergistic and unique terms of information naturally emerge from this formulation, allowing us to estimate multimodal interactions beyond redundancy. We test CoMM both in a controlled and in a series of real-world settings: in the former, we demonstrate that CoMM effectively captures redundant, unique and synergistic information between modalities. In the latter, CoMM learns complex multimodal interactions and achieves state-of-the-art results on the six multimodal benchmarks.},
	language = {en},
	urldate = {2024-12-29},
	publisher = {arXiv},
	author = {Dufumier, Benoit and Castillo-Navarro, Javiera and Tuia, Devis and Thiran, Jean-Philippe},
	month = sep,
	year = {2024},
	note = {arXiv:2409.07402 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	file = {PDF:/home/benoit/snap/zotero-snap/common/Zotero/storage/XHH7PSC5/Dufumier et al. - 2024 - What to align in multimodal contrastive learning.pdf:application/pdf},
}

@inproceedings{petiton_how_2024,
	title = {How and {Why} {Does} {Deep} {Ensemble} {Coupled} with {Transfer} {Learning} {Increase} {Performance} in {Bipolar} {Disorder} and {Schizophrenia} {Classification}?},
	url = {https://ieeexplore.ieee.org/abstract/document/10635777},
	doi = {10.1109/ISBI56570.2024.10635777},
	abstract = {Transfer learning (TL) and deep ensemble learning (DE) have recently been shown to outperform simple machine learning in classifying psychiatric disorders. However, there is still a lack of understanding as to why that is. This paper aims to understand how and why DE and TL reduce the variability of single-subject classification models in bipolar disorder (BD) and schizophrenia (SCZ). To this end, we investigated the training stability of TL and DE models. For the two classification tasks under consideration, we compared the results of multiple trainings with the same backbone but with different initializations. In this way, we take into account the epistemic uncertainty associated with the uncertainty in the estimation of the model parameters. It has been shown that the performance of classifiers can be significantly improved by using TL with DE. Based on these results, we investigate i) how many models are needed to benefit from the performance improvement of DE when classifying BD and SCZ from healthy controls, and ii) how TL induces better generalization, with and without DE. In the first case, we show that DE reaches a plateau when 10 models are included in the ensemble. In the second case, we find that using a pre-trained model constrains TL models with the same pre-training to stay in the same basin of the loss function. This is not the case for DL models with randomly initialized weights. 1},
	urldate = {2024-12-29},
	booktitle = {2024 {IEEE} {International} {Symposium} on {Biomedical} {Imaging} ({ISBI})},
	author = {Petiton, Sara and Grigis, Antoine and Dufumier, Benoit and Duchesnay, Edouard},
	month = may,
	year = {2024},
	note = {ISSN: 1945-8452},
	keywords = {bipolar disorder, brain anatomical MRI, deep ensemble learning, deep learning, Interpolation, Mental disorders, Predictive models, schizophrenia, Solid modeling, Training, transfer learning, Transfer learning, Uncertainty},
	pages = {1--5},
	file = {IEEE Xplore Abstract Record:/home/benoit/snap/zotero-snap/common/Zotero/storage/WDMDAVN4/10635777.html:text/html},
}

@misc{louiset_sepvae_2024,
	title = {{SepVAE}: a contrastive {VAE} to separate pathological patterns from healthy ones},
	shorttitle = {{SepVAE}},
	url = {http://arxiv.org/abs/2307.06206},
	doi = {10.48550/arXiv.2307.06206},
	abstract = {Contrastive Analysis VAE (CA-VAEs) is a family of Variational auto-encoders (VAEs) that aims at separating the common factors of variation between a background dataset (BG) (i.e., healthy subjects) and a target dataset (TG) (i.e., patients) from the ones that only exist in the target dataset. To do so, these methods separate the latent space into a set of salient features (i.e., proper to the target dataset) and a set of common features (i.e., exist in both datasets). Currently, all models fail to prevent the sharing of information between latent spaces effectively and to capture all salient factors of variation. To this end, we introduce two crucial regularization losses: a disentangling term between common and salient representations and a classification term between background and target samples in the salient space. We show a better performance than previous CA-VAEs methods on three medical applications and a natural images dataset (CelebA). Code and datasets are available on GitHub https: //github.com/neurospin-projects/ 2023\_rlouiset\_sepvae.},
	language = {en},
	urldate = {2024-12-29},
	publisher = {arXiv},
	author = {Louiset, Robin and Duchesnay, Edouard and Grigis, Antoine and Dufumier, Benoit and Gori, Pietro},
	month = apr,
	year = {2024},
	note = {arXiv:2307.06206 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning},
	file = {PDF:/home/benoit/snap/zotero-snap/common/Zotero/storage/NUG76S2N/Louiset et al. - 2024 - SepVAE a contrastive VAE to separate pathological patterns from healthy ones.pdf:application/pdf},
}
